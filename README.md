#数据来源（数据集在PeMS文件）：
数据来自美国的加利福尼亚州的洛杉矶市
第一个CSV文件是关于节点的表示情况，一共有307个节点，CSV文件其实就是一个直接能可视化的邻接矩阵，当然不是我们所需的那种
from和to表示的是节点，cost表示的是两个节点之间的直线距离（来表示权重），在本实验中，权重都为1.

第二个npz文件是交通流量的文件，时间范围是两个月（2018.1.1——2018.2.28），每5分钟测一次
307个节点，每个节点三个特征，然后统计了一个月每个节点的三个特征的变换，
也就是总共有307个站点，每个站点的时序数据有16992条，每条数据有三个特征.

#数据目标：
通过交通流量数据的处理(visualize_traffic_data.py)(traffic_dataset.py)，
主要是把拿到的数据的结构信息（邻接矩阵csv）和节点信息（流量数据npz）处理成了模型所需要的train_data和test_data

#GNN模型构建：
一个好的习惯是先把整体的网络框架搭建好，之后再去实现具体的模型，这样做的好处是在后面更换模型的时候只需要改一两行代码即可。
以上使用了GCN图卷积来预测交通流量，虽然考虑到了空间的影响，但是没有考虑时序上的影响，
所以能否加入RNN模型来考虑时序影响，进一步提高预测效果？
一些模型比如：STGCN, ASTGCN, DCRNN等，都是加入了时间的影响，值得借鉴．

#无联邦学习实验结果（运行traffic_prediction文件）：
基于数据pems07：307个节点

# 加入联邦学习（运行jupyter文件）


